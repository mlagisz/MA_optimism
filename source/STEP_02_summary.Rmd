---
title: "summary"
author: "ML"
date: "04/01/2020"
output: html_document
---

# MA of cognitive bias (optimism) in animal studies.

## STEP 02 - checking and summarising MA dataset

```{r setup, eval=TRUE, include=FALSE}
sessionInfo()
options(scipen=100)

knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
knitr::opts_chunk$set(fig.path="../plots/", fig.width=6.5, fig.height=4, fig.align="center")

#install.packages("devtools","fulltxt")
#library(readxl)
#update.packages("fulltxt")
#devtools::install_github("ropensci/rotl", dependencies = TRUE, build_vignette=TRUE)
#install.packages("rotl")
pacman::p_load(tidyverse, magrittr, fulltext, rotl, ape, dplyr, tidyr, rotl, fulltext, metafor, car)
source("../functions/functions.R") #load custom functions

#writeLines(capture.output(sessionInfo()), "./log_sessioninfo/sessionInfo.txt") #save session info into a text file
#writeLines(capture.output(sessionInfo()), paste0("./log_sessioninfo/sessionInfo_STEP02_", format(Sys.time(), "%d-%b-%Y %H.%M"), ".txt")) #save session info into a text file with timestamp in the file name
```

 * Load data   

```{r load data, eval=TRUE, include=FALSE} 
rm(list=ls()) # Clean up
dat <- read.csv("../data/MA_dataset_with_ES_subsets.csv")
dim(dat) #459  76
str(dat)
names(dat)
```

 * Data checks      

```{r check continuous variables, eval=FALSE, include=FALSE} 
#names(dat)

par(mfcol=c(1,2),mar=c(4,4,2,1),oma=c(0,0,0,0))
hist(dat$d)
hist(dat$Vd)

#plot(dat$d, 1/dat$Vd, col=dat$MeasureType, xlab = "Hedges g", ylab = "1/V Hedges g")

par(mfcol=c(1,1),mar=c(4,4,2,1),oma=c(0,0,0,0))
hist(as.numeric(dat$Year))
#dat$Year[which(dat$Year == "Unpublished")] <- "NA" #substitute "Unpublished" with NA
```

```{r check categorical variables, eval=FALSE, include=FALSE} 
unique(dat$ArticleID) #71 studies

#one-way tables
tabyl(dat$ArticleID) #N effect sizes per study
tabyl(dat$Species_Latin) #N effect sizes per species
tabyl(dat$Taxa) #mostly mammals and birds
tabyl(dat$Sex) #mosty females
tabyl(dat$Age) #mosty adults
tabyl(dat$Captive_Wild.caught) #mosty captive
tabyl(dat$AffectManipCat) #mostly stress
tabyl(dat$AffectManipTiming) #mostly long-term, then before
tabyl(dat$StudyDesign) #mostly between
tabyl(dat$CrossoverDesign)
tabyl(dat$Automated) #usually no (or no info)
tabyl(table(dat$Automated, dat$ArticleID)[2,]>0) #number of papers with automation 8
tabyl(dat$Blind) #usually no (or no info)
tabyl(table(dat$Blind, dat$ArticleID)[2,]>0) #number of papers with blinding 18
tabyl(dat$FoodDeprived) #usually no
tabyl(dat$CueTypeCat) #mostly spatial or visual
tabyl(dat$ComparisonCategory) #mostly Benign-Worse
tabyl(dat$ReinforcementCat) # mostly R-P, then R-Null
tabyl(dat$AmbigReinforced) #mostly no
tabyl(dat$TaskType) # mostly go/no-go
tabyl(dat$MeasureType) #201 latency, 258 proportion

#two-way tables
addmargins(table(dat$ArticleID, dat$MeasureType)) #5 studies with both latency and proportion
addmargins(table(dat$ArticleID, dat$Sex)) #a few studies with both sexes separated
addmargins(table(dat$ArticleID, dat$AffectManipCat)) #a few studies with two types of manipulation
addmargins(table(dat$ArticleID, dat$StudyDesign)) #one study with both within and between subject data
addmargins(table(dat$ArticleID, dat$ComparisonCategory)) #one study with more than one comparison type
addmargins(table(dat$Taxa, dat$ArticleID)) #mostly mammals and birds
sapply(tapply(dat$ArticleID, dat$Taxa, unique), length) #how many papers for each taxon
sapply(tapply(dat$ArticleID, dat$Taxa, unique), length)["mammal"]

#sapply(tapply(dat$ExperimentID, dat$ArticleID, unique), paste) #a few studies with more than one experiment
hist(sapply(tapply(dat$ExperimentID, dat$ArticleID, unique), length)) #a few studies with more than one experiment
#sapply(tapply(dat$GroupID, dat$ArticleID, unique), paste) #a few studies with more than one group of animals
hist(sapply(tapply(dat$GroupID, dat$ArticleID, unique), length)) #a few studies with more than one group of animals

table(dat$Blind, dat$StudyDesign) 
table(dat$StudyDesign, dat$Blind) 
table(dat$Blind, dat$ComparisonCategory) 
table(dat$StudyDesign, dat$ReinforcementCat) 
table(dat$Blind, dat$ReinforcementCat) 
table(dat$FoodDeprived, dat$ReinforcementCat) 
table(dat$MeasureType, dat$Sex) 
table(dat$TaskType, dat$MeasureType)
```

```{r data sources by article, eval=FALSE, include=FALSE}
dat %>% group_by(ArticleID) %>% distinct(DataSource) -> dat_sources
dat_sources
#View(dat_sources)
#grep("raw", dat_sources$DataSource, ignore.case=TRUE, value=TRUE) #not from authors
grep("auth", dat_sources$DataSource, ignore.case=TRUE, value=TRUE)
length(grep("auth", dat_sources$DataSource, ignore.case=TRUE, value=TRUE))
dat_sources[grep("auth", dat_sources$DataSource, ignore.case=TRUE, value=FALSE), 2] #list of articleIDs

#NOTE: these are only incuded studies, we also got several data sets for studies that were not included in the final data set, so the numbers mentioned in the MS are higher
```


* Simple boxplots

```{r boxplots, eval=FALSE, include=FALSE} 
par(mar=c(12,4,2,0))
boxplot(dat$d ~ dat$Species_Latin, las=2, ylab="Hg", varwidth=TRUE)
par(mar=c(4,4,2,0))
boxplot(dat$d ~ dat$Taxa, ylab="Hg", varwidth=TRUE)
boxplot(dat$d ~ dat$Sex, ylab="Hg", varwidth=TRUE)
boxplot(dat$d ~ dat$MeasureType, ylab="Hg", varwidth=TRUE)
boxplot(dat$d ~ dat$TaskType, ylab="Hg", varwidth=TRUE)
boxplot(dat$d ~ dat$AffectManipCat, ylab="Hg", varwidth=TRUE)
boxplot(dat$d ~ dat$StudyDesign, ylab="Hg", varwidth=TRUE)
boxplot(dat$d ~ dat$CrossoverDesign, ylab="Hg", varwidth=TRUE)
boxplot(dat$d ~ dat$Blind, ylab="Hg", varwidth=TRUE)
boxplot(dat$d ~ dat$Automated, ylab="Hg", varwidth=TRUE)
boxplot(dat$d ~ dat$FoodDeprived, ylab="Hg", varwidth=TRUE)
boxplot(dat$d ~ dat$AmbigReinforced, ylab="Hg", varwidth=TRUE)
boxplot(dat$d ~ dat$CueTypeCat, ylab="Hg", varwidth=TRUE)
boxplot(dat$d ~ dat$ComparisonCategory, ylab="Hg", varwidth=TRUE)
boxplot(dat$d ~ dat$AffectManipTiming, ylab="Hg", varwidth=TRUE)
boxplot(dat$d ~ dat$ReinforcementCat, ylab="Hg", varwidth=TRUE)

par(mar=c(10,4,2,0))
boxplot(dat$d ~ dat$TaskType + dat$MeasureType, las=2, ylab="Hg", varwidth=TRUE)
```

* TABLE OF INCLUDED PUBLICATIONS

```{r table inculded papers, eval=FALSE, include=FALSE} 
dat_gr <-  group_by(dat, ArticleID)
countES <- dplyr::summarise(dat_gr, k=n())
pastecols <- dplyr::summarise(dat_gr, first(Species_Latin), toString(unique(Taxa)), toString(unique(Captive_Wild.caught)), toString(unique(Sex)), toString(unique(Age)), toString(unique(AffectManipCat)), toString(unique(AffectManipTiming)), toString(unique(FoodDeprived)), toString(unique(TaskType)),toString(unique(CueTypeCat)),toString(unique(AmbigReinforced)), toString(unique(StudyDesign)), toString(unique(Blind)), toString(unique(Automated)), toString(unique(ComparisonCategory)), toString(unique(ReinforcementCat)), toString(unique(MeasureType)))

tab <- data.frame(pastecols, countES$k)
names(tab) <- c("Reference", "Species", "Taxon", "Origin", "Sex", "Age", "Manipulation", "Manipulation timing", "Food deprivation", "Task type","Cue", "Ambiguous reinforced", "Design", "Blinding", "Automation", "Comparison", "Reinforcement", "Measure", "k")
tab <- dplyr::arrange(tab, Reference)
write.csv(tab,"./tables/table_included_papers_2019.csv")

#for Systematic Review summary diagram (Figure 3 - to be created in PowerPoint):

table(tab$Taxon)
table(tab$Origin)
table(tab$Sex)
table(tab$Age)
table(tab$Manipulation)
table(tab$Comparison)
table(tab$`Manipulation timing`)
table(tab$Design)

table(tab$`Task type`)
table(tab$Cue)
table(tab$Reinforcement)
table(tab$`Ambiguous reinforced`)
table(tab$`Food deprivation`)
table(tab$Measure)
table(tab$Automation)
table(tab$Blind)

table(tab$Species)
```


```{r check subsets, eval=FALSE, include=FALSE} 
str(dat)
names(dat)
table(dat$ScalePoint)
table(dat$max_ES)
table(dat$biggest_ES)
table(dat$biggest_meandir)

table(dat$max_ES, dat$biggest_ES) #different for 38 studies
table(dat$max_ES, dat$biggest_meandir) #different for 27 studies
table(dat$biggest_ES, dat$biggest_meandir) #different for 13 studies

table(dat$max_ES == dat$biggest_ES) #different for 76/2=38 studies
table(dat$max_ES == dat$biggest_meandir) #different for 54/2=27 studies
table(dat$biggest_ES == dat$biggest_meandir) #different for 26/2=13 studies
```




*  EXTRA: Is there correlation between  measurements from the same experiment reported as latency and proportion?

```{r prop lat subset - correlation, eval=TRUE, include=FALSE} 
#### look for studies that have both prop and lat
names(dat)

#table(dat$MeasureType, dat$ArticleID) # Looks correct
#table(dat$MeasureType, dat$ExperimentID) 
dat_lat <- filter(dat, MeasureType=="latency")
dat_prop <- filter(dat, MeasureType=="proportion")
dat_horiz <- merge(dat_lat, dplyr::select(dat_prop, ExperimentID, ScalePoint, d, Vd), by = c("ExperimentID", "ScalePoint"))
dat_horiz <- droplevels(dat_horiz)
str(dat_horiz) #21 ES from 5 articles/experiments
unique(dat_horiz$ArticleID) #CHECK: Bethell2012   Douglas2012   Guldimann2015 Harding2004   Deakin2016
length(unique(dat_horiz$ExperimentID)) #5 experimentswhere both latency and proportion reported
length(unique(dat_horiz$ArticleID)) #5 studies where both latency and proportion reported
#table(dat_horiz$ExperimentID, dat_horiz$ScalePoint)
#table(dat_horiz$ExperimentID, dat_horiz$ArticleID)
plot(dat_horiz$d.x, dat_horiz$d.y) 
plot(dat_horiz$d.x, dat_horiz$d.y, col=dat_horiz$ExperimentID) #make it prettier
lat_prop_cor <- cor.test(dat_horiz$d.x, dat_horiz$d.y) # Pearson's product-moment correlation 

str(lat_prop_cor)
round(lat_prop_cor$statistic, 3) #t
round(lat_prop_cor$parameter, 3) #df
round(lat_prop_cor$p.value, 3)
round(lat_prop_cor$estimate, 3)

#do we need more complex model to account for non-independence and to weight by variance? after adding these cor will be weaker?
```

```{r prop lat subset maxES - correlation, eval=TRUE, include=FALSE} 
#### look for studies that have both prop and lat
dat_horiz <- droplevels(dat_horiz)
str(dat_horiz)
dat_horiz_maxES <- filter(dat_horiz, max_ES==1)
str(dat_horiz_maxES)
length(unique(dat_horiz_maxES$ExperimentID)) #5 experiments where both latency and proportion reported
length(unique(dat_horiz_maxES$ArticleID)) #5 studies where both latency and proportion reported
#table(dat_horiz_maxES$ExperimentID, dat_horiz_maxES$ScalePoint)
#table(dat_horiz_maxES$ExperimentID, dat_horiz_maxES$ArticleID)
plot(dat_horiz_maxES$d.x, dat_horiz_maxES$d.y) 
plot(dat_horiz_maxES$d.x, dat_horiz_maxES$d.y, col=dat_horiz_maxES$ExperimentID) #make it prettier
lat_prop_cor_max <- cor.test(dat_horiz_maxES$d.x, dat_horiz_maxES$d.y) # Pearson's product-moment correlation NS
```


```{r prop lat subset - OTHER WAYS - NOT SURE, eval=FALSE, include=FALSE} 
library(nlme)
res_cor <- lme(d.y ~ d.x, random=list(~1|ArticleID), correlation=corGaus(form=~1|ArticleID), data=dat_horiz)
res_cor

#correlations within each experiment_ID
dat_horiz %>% group_by(ExperimentID) %>%  summarize(COR=cor(d.x, d.y)) #note these are based on max 3 data points

#using metafor multivariate model
dat_horiz.y <- subset(dat_horiz, select=-c(d.x,Vd.x))
dat_horiz.y$MeasureType <- "y"
dat_horiz.x <- subset(dat_horiz, select=-c(d.y,Vd.y))
dat_horiz.x$MeasureType <- "x"
library(data.table)
setnames(dat_horiz.y, old = c('d.y','Vd.y'), new = c('d','Vd'))
setnames(dat_horiz.x, old = c('d.x','Vd.x'), new = c('d','Vd'))
dat_horiz.xy <- rbind(dat_horiz.x, dat_horiz.y)
str(dat_horiz.xy)
#dat_horiz.xy$MeasureType <- factor(datallfm$sex, levels=c("female","male"))
VCV.xy <- make_VCV_matrix(data = dat_horiz.xy, V = "Vd", cluster = "ExperimentID", obs = "EffectID") #make_VCV_matrix is a custom function by Dan Noble loaded from from functions.R
dim(VCV.xy) 
res.xy <- rma.mv(d, VCV.xy, mods = ~ MeasureType - 1, data = dat_horiz.xy, random = ~ MeasureType | ExperimentID, struct = "UN")
res.xy
### contrast for differences by MeasureType
anova(res.xy, L=c(1,-1))
```

### WRITE 

```{r other data subsets, eval=TRUE, include=FALSE}
#### SUBSET with only ambiguous cue data points:
dat_amb <- dplyr::filter(dat, ScalePoint %in% c("MID","NN","NP"))
dim(dat_amb) #269

### SUBSETS from all data (proportion and latency) by picking only one ES from the curves/tests with >1 scale points (we use the prepared columns that already code these choices):
dat_max_ES <- dplyr::filter(dat, max_ES == 1) #subset by picking maximum ES from each curve (i.e. get the most positive=optimistic response available)
dim(dat_max_ES) #108

dat_max_absES <- dplyr::filter(dat, biggest_ES == 1) #subset by picking ES with the biggest absolute value from each curve (i.e. get the most positive or negatve response available)
dim(dat_max_absES) #108

dat_max_meanES <- dplyr::filter(dat, biggest_meandir == 1) #subset by picking ES from each curve which has the biggest absolute value in the direction of the mean value of all ES from the curve (i.e. biggest in the overall direction of the response)
dim(dat_max_meanES) #108

dat_MID_ES <- dplyr::filter(dat, ScalePoint == "MID") #subset by picking only middle (MID) ES from each curve
dim(dat_MID_ES) 
```

**For Methods**   
Comparison of data subsets dat_max_meanES and dat_max_absES:    

`r table(dat_max_meanES$EffectID==dat_max_absES$EffectID)[2]` effect sizes same   
`r table(dat_max_meanES$EffectID==dat_max_absES$EffectID)[1]` effect sizes different   
`r length(dat_max_meanES$EffectID)` effect sizes total   
`r round((table(dat_max_meanES$EffectID==dat_max_absES$EffectID)[1]/length(dat_max_meanES$EffectID)*100),1)`% effect sizes different   

Comparison of data subsets dat_MID_ES and dat_max_absES:    

`r table(dat_MID_ES$EffectID==dat_max_absES$EffectID)[2]` effect sizes same   
`r table(dat_MID_ES$EffectID==dat_max_absES$EffectID)[1]` effect sizes different   
`r length(dat_MID_ES$EffectID)` effect sizes total   
`r round((table(dat_MID_ES$EffectID==dat_max_absES$EffectID)[1]/length(dat_max_meanES$EffectID)*100),1)`% effect sizes different   


**Results**   
*Data set*   
Results from the literature searches are presented in a PRISMA diagram (Figure 2). The list of included studies sis provided in Supplementary Table S2. Excluded studies, with reasons for exclusion, are listed in Supplementary Table S3. To retrieve missing data or additional information we contacted 39 authors about 35 studies. We attained raw data for 18 studies and additional information for 10 studies. Ultimately, we extracted `r dim(dat)[1]` effect sizes, representing `r length(unique(dat$ExperimentID))` experiments published in `r length(unique(dat$ArticleID))` articles. The studies were performed on `r length(unique(dat$Species_Latin))` species ranging from honeybees to monkeys. The main characteristics of the included studies are summarised in Figure 3 identifying significant variation in study subjects and methodologies. Individual studies contributed between `r min(table(dat$ArticleID))` and `r max(table(dat$ArticleID))` effect sizes to our final data set.

Mammals were the best-represented taxonomic group (`r sapply(tapply(dat$ArticleID, dat$Taxa, unique), length)["mammal"]` out of `r sum(sapply(tapply(dat$ArticleID, dat$Taxa, unique), length))`  studies; `r table(dat$Taxa)["mammal"]` out of `r sum(table(dat$Taxa))` effect sizes) and almost all studies were performed on captive animals (`r sapply(tapply(dat$ArticleID, dat$Captive_Wild.caught, unique), length)["captive"]` studies; `r table(dat$Captive_Wild.caught)["captive"]` effect sizes). Females were more frequently used in experiments than males or mixed-sex groups (`r table(dat$Sex)["female"]`, `r table(dat$Sex)["male"]`, `r table(dat$Sex)["mixed-sex"]` effect sizes, respectively; for the numbers of studies see Figure 3), and adults were more commonly used than juveniles (`r table(dat$Age)["adult"]` and `r table(dat$Age)["juvenile"]` effect sizes, respectively). Most often, affect manipulation was a form of stress induction compared to standard/benign conditions (benign-worse comparison: `r table(dat$ComparisonCategory)["Benign-Worse"]` effect sizes). Enrichment compared to control/benign conditions was the next most common manipulation (better-benign comparison: `r table(dat$ComparisonCategory)["Better-Benign"]` effect sizes), and a few studies compared positive treatments (e.g., enrichment) to negative treatments (e.g., handling) (better-worse comparison: `r table(dat$ComparisonCategory)["Better-Worse"]` effect sizes). Manipulations were usually long-term (`r table(dat$AffectManipTiming)["long-term"]` effect sizes), lasting for days or weeks before affect was measured.

Between-subject designs (independent groups of animals exposed to manipulation or control/benign treatment) accounted for `r table(dat$WithinBetween)["between"]` effect sizes and within-subject designs accounted for `r table(dat$WithinBetween)["within"]` effect sizes (`r table(dat$StudyDesign)["within (before-after)"]` before-after, `r table(dat$StudyDesign)["within (crossover)"]` cross-over). Go/no-go tasks dominated over active choice tasks (`r table(dat$TaskType)["go/no-go"]` and `r table(dat$TaskType)["active choice"]` effect sizes, respectively). Spatial and visual cues were most commonly used in judgement bias tests `r table(dat$CueTypeCat)["spatial"]` and `r table(dat$CueTypeCat)["visual"]` effect sizes respectively), and reward-punishment training schemes were more common than reward-null (`r table(dat$ReinforcementCat)["R-P"]` and `r table(dat$ReinforcementCat)["R-Null"]` effect sizes, respectively), with the remaining studies using different reward strengths. Most studies did not report whether the personnel performing measurements of animal behaviour were blinded to treatments, or whether the measurements were automated. Finally, outcome measures were as likely to be reported as latencies as proportions (`r table(dat$MeasureType)["proportion"]` and `r table(dat$MeasureType)["latency"]` effect sizes, respectively). Only `r length(unique(dat_horiz$ArticleID))` studies with go/no-go tasks reported the judgement bias test measurements as both latency and proportion, which were moderately correlated (*r* = `r round(lat_prop_cor$estimate, 3)`, *t* = `r round(lat_prop_cor$statistic, 3)`, *df* = `r round(lat_prop_cor$parameter, 3)`, *p*-value = `r round(lat_prop_cor$p.value, 3)`; for the data subset with only largest effect sizes from each experiment to reduce non-independence: *r* = `r round(lat_prop_cor_max$estimate, 3)`, *t* = `r round(lat_prop_cor_max$statistic, 3)`, *df* = `r round(lat_prop_cor_max$parameter, 3)`, *p*-value = `r round(lat_prop_cor_max$p.value, 3)`).

###############################################################################

NEXT: "STEP_03_models.Rmd"
