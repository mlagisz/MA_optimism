---
title: "preprocessing"
author: "ML"
date: "11/29/2017"
output: html_document
---

# MA of cognitive bias (optimism) in animal studies.

## STEP1 - preprocessing data

The outcome measures are either letencies or proportions.
In this version of code we create two separate data frames to hold proportion and latency datasets 
(originally script: "Preparation and cleaning of proportion and latency data V2.R")

```{r setup}

sessionInfo() #R version 3.4.2 (2017-09-28)
#Platform: x86_64-apple-darwin15.6.0 (64-bit)
#Running under: macOS Sierra 10.12.6
options(scipen=100)

#install.packages("car", "meta", "metafor", "ape", "dplyr", "ggplot2", "scales", "cowplot")
#install.packages("devtools","fulltxt")
#library(readxl)
#update.packages("fulltxt")
#library(fulltext)
#devtools::install_github("ropensci/rotl", dependencies = TRUE, build_vignette=TRUE)
#install.packages("rotl")
#library(rotl)
#library(ape)
#library(phytools)
#library(dplyr)
#library(tidyr)
#library(ggplot2)
#library(scales)
#library(easyGgplot2)
#library(cowplot)

pacman::p_load(tidyverse, magrittr, fulltext, rotl, ape, dplyr, tidyr)
source("functions.R")
```


```{r load custom functions}
#### Functions for calculating effect size for proportion data modified by ML&SN from the function (originally by A M Senior): we use qlogis(meanproportion) and SD=sqrt(pi^2/3)
#### Calc.d calculates Hedges'd (sometimes g), which is 'unbiased for small sample size'. Cohen's d can be returned using adjusted = F.
#### Calc.SE.d calculates d values given the necessery n's

## Calc.d.percA calculates the effect size d for proportion data with fixed SD:
# Calc.d.propA <- function(Worse, WorseSD, WorseN, Better, BetterSD, BetterN, adjusted=T){
#   #logit SD, divide by 100 to get proportions from procentage data
#   logitBetter <- qlogis(Better/100)
#   logitWorse <- qlogis(Worse/100)
#   #variance from SD
#   VarianceBetter <- pi^2/3
#   VarianceWorse <- pi^2/3
#   #sPooled 
#   sPooled <- sqrt(((BetterN-1)*VarianceBetter + (WorseN-1)*VarianceWorse)/(BetterN + WorseN - 2))
#   #d and Hedges d
#   d <- (logitBetter-logitWorse)/sPooled
#   H.d <- d * (1-(3/ (4 * (BetterN + WorseN -2) -1)))
#   if(adjusted==T){return(H.d)}
#   if(adjusted==F){return(d)}
# }


## Calc.d.propB calculates the effect size d for proportion data with non-fixed SD:
Calc.d.propB <- function(Worse, WorseSD, WorseN, Better, BetterSD, BetterN, adjusted=T, DataType="natural"){
#if natural data then logit means and SDs, divide by 100 to get proportions from procentage data
if (DataType == "natural")
{
  logitBetter <- qlogis(Better/100)
  logitWorse <- qlogis(Worse/100)
  SDlogitBetter <- (BetterSD/100) * ( 1/(Better/100) + 1/(1-(Better/100)) )
  SDlogitWorse <- (WorseSD/100) * ( 1/(Worse/100) + 1/(1-(Worse/100)) )
}
#if logit data then no need to transform
if (DataType == "logit")
{
  logitBetter <- Better
  logitWorse <- Worse
  SDlogitBetter <- BetterSD
  SDlogitWorse <- WorseSD
}
#variance
VarianceBetter <- SDlogitBetter^2
VarianceWorse <- SDlogitWorse^2
#sPooled 
sPooled <- sqrt(((BetterN-1)*VarianceBetter + (WorseN-1)*VarianceWorse)/(BetterN + WorseN - 2))
#d and Hedges d
d <- (logitBetter-logitWorse)/sPooled
H.d <- d * (1- (3/ (4 * (BetterN + WorseN -2) -1)))
if(adjusted==T){return(H.d)}  
  if(adjusted==F){return(d)}
}


## Calc.d.lat calculates the effect size d for latency data:
Calc.d.lat_raw <- function(Worse, WorseSD, WorseN, Better, BetterSD, BetterN, adjusted=T){
  VarianceBetter <- BetterSD^2
  VarianceWorse <- WorseSD^2
  #sPooled is calculated with the logged variables
  sPooled <- sqrt(((BetterN-1)*VarianceBetter + (WorseN-1)*VarianceWorse)/(BetterN + WorseN -2))
  #d and Hedges d
  d <- (Better-Worse)/sPooled
  H.d <- d * (1-(3/ (4 * (BetterN + WorseN -2) -1)))
  if(adjusted==T){return(-H.d)} #Reversing sign on latency data to match proportion data. #Now positive values means optimistic for both lat and prop data.
  if(adjusted==F){return(-d)} #Reversing sign on latency data to match proportion data. #Now positive values means optimistic for both lat and prop data.
}

## Calc.d.lat calculates the effect size d for latency data (after log-transformation):
Calc.d.lat_log <- function(Worse, WorseSD, WorseN, Better, BetterSD, BetterN, adjusted=T){
  #log mean and SDn
  logBetter <- log(Better)
  logWorse <- log(Worse)
  #variance
  VarianceBetter <- (BetterSD/Better)^2
  VarianceWorse <- (WorseSD/Worse)^2
  #sPooled is calculated with the logged variables
  sPooled <- sqrt(((BetterN-1)*VarianceBetter + (WorseN-1)*VarianceWorse)/(BetterN + WorseN -2))
  #d and Hedges d
  d <- (logBetter-logWorse)/sPooled
  H.d <- d * (1-(3/ (4 * (BetterN + WorseN -2) -1)))
  if(adjusted==T){return(-H.d)} #Reversing sign on latency data to match proportion data. #Now positive values means optimistic for both lat and prop data.
  if(adjusted==F){return(-d)} #Reversing sign on latency data to match proportion data. #Now positive values means optimistic for both lat and prop data.
}

# #Standard error for d
# Calc.SE.d <- function(WorseN, BetterN, d){
#   SE <- sqrt(((WorseN + BetterN) / (WorseN * BetterN) ) + ( (d^2) / (2 * (WorseN + BetterN - 2)))) #between study design
#   SE <- sqrt(( (d^2) / (2 * (WorseN  - 1)))) #within study design - assuming the perfect correlation (conservative estimate)
#   return(SE)
# }


#Standard error for d with within - between subject study design option
Calc.SE.d <- function(WorseN, BetterN, d, WithinBetween="between"){
  if (WithinBetween == "between") {SE <- sqrt(((WorseN + BetterN) / (WorseN * BetterN) ) + ( (d^2) / (2 * (WorseN + BetterN - 2))))} #for between-subject study design
  if (WithinBetween == "within") {SE <- sqrt(1/WorseN + ((d^2) / (2 * (WorseN  - 1))))} #for within-subject study design - assuming 0.5 correlation (conservative estimate)
  return(SE)
}
```

################################################# Load MA dataset #############################
                                        
```{r MA_dataset load}                                          
#load proportion data from text file:
dat <- read.csv("data/MA_dataset_2017.csv")
names(dat)
tail(dat)
str(dat) 
dim(dat) #272 62

unlist(lapply(dat, function(x) sum(is.na(x)))) #how many NA per numerical column
dat <- dplyr::select(dat, -c(X, X.1)) #get rid of rows with no data (last 2 columns)
dat <- dplyr::filter(dat, !is.na(Better)) #get rid of rows with no data (last empty row)
dat <- droplevels(dat)
table(dat$DataSE) #6 SE imputed? check
dplyr::filter(dat, DataSE == "no") #Destrez2016, Hernandez2015 (3 rows each)
dat <- dplyr::filter(dat, DataSE != "no") #get rid of rows with missing SE
dat <- droplevels(dat)
table(dat$WithinBetween) # 168 "between", 97 "within"
table(dat$StudyDesign, dat$WithinBetween) #good overlap
dim(dat)  #265  60

### SUBSETS by MeasureType
table(dat$MeasureType) # 138 "latency", 127 "proportion"
dat_lat <- dplyr::filter(dat, MeasureType == "latency") #subset latency data
dim(dat_lat) 
dat_prop <- dplyr::filter(dat, MeasureType == "proportion") #subset proportion data
dim(dat_prop) 
```



################################################# Proportion data #############################
                                        
```{r prop data check, eval=FALSE}  
#which means are already logit-transformed?
table(dat_prop$DataScale) #6 data points on logit scale
dat_prop[which(dat_prop$DataScale == "logit"), ]

#find rows with means or SD = 0 for natural scale proportion data
dat_prop[which(dat_prop$Better == 0 & dat_prop$DataScale == "natural"), ] #none
dat_prop[which(dat_prop$BetterSD == 0 & dat_prop$DataScale == "natural"), ] #none
dat_prop[which(dat_prop$Worse == 0 & dat_prop$DataScale == "natural"), ] #2 rows
dat_prop[which(dat_prop$WorseSD == 0 & dat_prop$DataScale == "natural"), ] #2 rows
dat_prop[which(dat_prop$Worse < 0.5 & dat_prop$DataScale == "natural"), ]$Worse #smallest value after 0 is 0.01
dat_prop$Worse[which(dat_prop$Worse == 0 & dat_prop$DataScale == "natural")] <- 0.01 #substitute the 0 values with 0.01
dat_prop[which(dat_prop$WorseSD < 0.5 & dat_prop$DataScale == "natural"), ]$WorseSD #smallest value after 0 is 0.014
dat_prop$WorseSD[which(dat_prop$WorseSD == 0 & dat_prop$DataScale == "natural")] <- 0.01 #substitute the 0 values with 0.01

#find rows with means / 100 > 1 (more than 100%)
dat_prop[which(dat_prop$Better/100 >= 1 & dat_prop$DataScale == "natural"), ] #1 row
dat_prop[which(dat_prop$Worse/100 >= 1 & dat_prop$DataScale == "natural"), ] #1 row
dat_prop[which(dat_prop$Worse/100 > 0.9 & dat_prop$DataScale == "natural"), ]$Worse #largest value before 100 is 99.147
dat_prop$Worse[which(dat_prop$Worse/100 >= 1 & dat_prop$DataScale == "natural")] <- 99.2 #substitute the >100% value with 99.2
dat_prop[which(dat_prop$Better/100 > 0.9 & dat_prop$DataScale == "natural"), ]$Better #largest value before 100 is 99.661
dat_prop$Better[which(dat_prop$Better/100 >= 1 & dat_prop$DataScale == "natural")] <- 99.7 #substitute the >100% value with 99.7

#plot
hist(dat_prop$Worse[which(dat_prop$DataScale == "natural")])
hist(qlogis(dat_prop$Worse[which(dat_prop$DataScale == "natural")]/100))
hist(dat_prop$Better[which(dat_prop$DataScale == "natural")])
hist(qlogis(dat_prop$Better[which(dat_prop$DataScale == "natural")]/100))
#qlogis(dat_prop$Worse[which(dat_prop$DataScale == "natural")]/100)
```


```{r prop calculate ES}
#subset natural data and calculate Hd
dat_prop_nat <- dat_prop[dat_prop$DataScale == "natural", ]
dat_prop_nat$Hd <- Calc.d.propB(dat_prop_nat$Worse, dat_prop_nat$WorseSD, dat_prop_nat$WorseN, dat_prop_nat$Better, dat_prop_nat$BetterSD, dat_prop_nat$BetterN, DataType="natural")

#subset logit data and calculate Hd
dat_prop_logit <- dat_prop[dat_prop$DataScale == "logit", ]
dat_prop_logit$Hd <- Calc.d.propB(dat_prop_logit$Worse, dat_prop_logit$WorseSD, dat_prop_logit$WorseN, dat_prop_logit$Better, dat_prop_logit$BetterSD, dat_prop_logit$BetterN, DataType="logit")

#merge back the subsets
dat_prop <- rbind(dat_prop_nat, dat_prop_logit)
names(dat_prop)
dat_prop$Hd
hist(dat_prop$Hd)
dat_prop[dat_prop$Hd > 4, ] #look at 2 effect sizes > 4 
dat_prop[dat_prop$Hd == 0, ] #look at Hd = 0 

### calculate variance of Hd (VHd) - need to take into account study design within vs. between
dat_prop_B <- dat_prop[dat_prop$WithinBetween == "between", ] #subset between
dat_prop_B$HdVar <- Calc.SE.d(dat_prop_B$WorseN, dat_prop_B$BetterN, dat_prop_B$Hd)
#subset within
dat_prop_W <- dat_prop[dat_prop$WithinBetween == "within", ]
dat_prop_W$HdVar <- Calc.SE.d(dat_prop_W$WorseN, dat_prop_W$BetterN, dat_prop_W$Hd)
#merge back the subsets
dat_prop <- rbind(dat_prop_B, dat_prop_W)
hist(dat_prop$HdVar)
#dat_prop$HdVar
dat_prop[dat_prop$HdVar == 0, ] #none

# #remove odd ones
# #dat_prop[dat_prop$ArticleID == "Doyle2011b", ]
# dat_prop_ok <- dat_prop[dat_prop$ArticleID != "Doyle2011b", ] #sheep long terms stress. Tested 3 times ..habituation? Use day 1?
# dim(dat_prop_ok)
# hist(dat_prop_ok$Hd.B)
# 
# #unique(dat_prop$ArticleID)
# #dat_prop_ok$comp_ID <- paste("comp", 1:nrow(dat_prop_ok), sep="_") #add column with comparison ID (unique ID for effect sizes within given dat_propa set)
table(dat_prop$ScientificName)
#Make new column in the data frame and adjust species names there:
dat_prop$Species_Latin <- as.character(dat_prop$ScientificName)
unique(dat_prop$Species_Latin)
#dat_prop$Species_Latin[which(dat_prop$Species_Latin == "Cebus apella")] <- "Sapajus_apella"


#write.csv(dat_prop, "data/data_proportions_with.csv", row.names = FALSE)
```

############## TREE prop

Prepare phyogenetic tree for the species in this data subset  

```{r prop tree}
#The function tnrs_match_names returns a data frame that lists the Open Tree identifiers as
#well as other information to help users ensure that the taxa matched are the correct ones

species_list <- as.character(unique(dat_prop$Species_Latin))
taxa <- tnrs_match_names(names = species_list) #call rotl function to find these species on OTL
#taxa
tree <- tol_induced_subtree(ott_ids= taxa[["ott_id"]])
tree
plot(tree, cex=.8, label.offset =.1, no.margin = TRUE)
str(tree)
is.binary.tree(tree) #TRUE
is.ultrametric(tree) #FALSE - Error: no branch lengths! (will simulate later)
tree$node.label <- "" # remove
tree$tip.label #clean these up
tree$tip.label <- gsub("_ott.*","", tree$tip.label)
plot(tree, cex=.8, label.offset =.1, no.margin = TRUE)
tree <- collapse.singles(tree)
tree$tip.label # column "animal" in the dataset should match these names exactly! 
intersect(unique(dat_prop$Species_Latin), tree$tip.label) #all are matching
#setdiff(unique(dat_prop$ScientificName), tree$tip.label) #0 need to be changed from
#setdiff(tree$tip.label, unique(dat_prop$ScientificName)) #2 need to be changed to
tree$tip.label[tree$tip.label==""]
### computing branch lengths
tree_bl <- compute.brlen(tree)
plot(tree_bl)
is.binary.tree(tree_bl)
is.ultrametric(tree_bl)
str(tree_bl)
write.tree(tree_bl,file="data/tree_branch_lengths_prop.tre")
#tree_prop <- read.tree(file="data/tree_branch_lengths_prop.tre")
#if you need to remove some species from the tree later (due to working on the subset of the data), use drop.tip function, for example:
#tree_noInsect <- drop.tip(tree, "Bombus_terrestris_audax") # remove "Bombus_terrestris_audax" from the tree
write.csv(dat_prop, "data/data_proportions_with_ES_tree.csv", row.names = FALSE)
```


############################################### latency data ########################################

```{r lat calculate ES}  
names(dat_lat)
tail(dat_lat)
dim(dat_lat)

##### use modified functions to calculate Hedges d:
#dat_lat$Hd <- Calc.d.lat(dat_lat$Worse, dat_lat$WorseSD, dat_lat$WorseN, dat_lat$Better, dat_lat$BetterSD, dat_lat$BetterN)

# # using raw (untransformed) data
# dat_lat$Hd_raw <- Calc.d.lat_raw(dat_lat$Worse, dat_lat$WorseSD, dat_lat$WorseN, dat_lat$Better, dat_lat$BetterSD, dat_lat$BetterN)
# hist(dat_lat$Hd_raw)
# range(dat_lat$Hd_raw)
# 
# # variance of Hedges d
# #dat_lat$HdVar <- Calc.SE.d(dat_lat$WorseN, dat_lat$BetterN, dat_lat$Hd)
# #for raw (untransformed) data
# dat_lat_B <- dat_lat[dat_lat$WithinBetween == "between", ]
# dat_lat_B$HdVar_raw <- Calc.SE.d(dat_lat_B$WorseN, dat_lat_B$BetterN, dat_lat_B$Hd_raw, WithinBetween="between")
# #subset within
# dat_lat_W <- dat_lat[dat_lat$WithinBetween == "within", ]
# dat_lat_W$HdVar_raw <- Calc.SE.d(dat_lat_W$WorseN, dat_lat_W$BetterN, dat_lat_W$Hd_raw, WithinBetween="within")
# #merge back the subsets
# dat_lat_ES <- rbind(dat_lat_B, dat_lat_W)
# hist(dat_lat_ES$HdVar_raw)
# range(dat_lat_ES$HdVar_raw)


#using log (transformed) data
dat_lat$Hd <- Calc.d.lat_log(dat_lat$Worse, dat_lat$WorseSD, dat_lat$WorseN, dat_lat$Better, dat_lat$BetterSD, dat_lat$BetterN)
hist(dat_lat$Hd)
range(dat_lat$Hd)

#variance of Hedges d
#dat_lat_ES$HdVar <- Calc.SE.d(dat_lat_ES$WorseN, dat_lat_ES$BetterN, dat_lat_ES$Hd)
#for log (transformed) data
dat_lat_B <- dat_lat[dat_lat$WithinBetween == "between", ]
dat_lat_B$HdVar <- Calc.SE.d(dat_lat_B$WorseN, dat_lat_B$BetterN, dat_lat_B$Hd)
#subset within
dat_lat_W <- dat_lat[dat_lat$WithinBetween == "within", ]
dat_lat_W$HdVar <- Calc.SE.d(dat_lat_W$WorseN, dat_lat_W$BetterN, dat_lat_W$Hd)
#merge back the subsets
dat_lat_ES <- rbind(dat_lat_B, dat_lat_W)
#hist(dat_lat_ES$HdVar)
range(dat_lat_ES$HdVar)

#plot(dat_lat_ES$Hd_raw, dat_lat_ES$Hd) #mostly very similar
#plot(dat_lat_ES$HdVar_raw, dat_lat_ES$HdVar) #mostly very similar

#raw data plot - difference Better-Worse
# boxplot(dat_lat_ES$Better - dat_lat_ES$Worse)
# boxplot(dat_lat_ES$Better - dat_lat_ES$Worse ~dat_lat_ES$Category, varwidth=TRUE)
# boxplot(dat_lat_ES$Better - dat_lat_ES$Worse ~dat_lat_ES$ScalePoint, varwidth=TRUE)
# plot(dat_lat_ES$Better - dat_lat_ES$Worse)
# plot(dat_lat_ES$Better, dat_lat_ES$Better - dat_lat_ES$Worse )

dat_lat <- droplevels(dat_lat_ES)

table(dat_lat$ScientificName)
dat_lat$Species_Latin <- as.character(dat_lat$ScientificName)
unique(dat_lat$Species_Latin)

write.csv(dat_lat, "data/data_latencies_with_ES.csv", row.names = FALSE)
```

############## TREE latencies

Create phylogenetic tree for the species in this dataset   

```{r lat tree} 
#The function tnrs_match_names returns a data frame that lists the Open Tree identifiers as
#well as other information to help users ensure that the taxa matched are the correct ones
names(dat_lat)

species_list <- as.character(unique(dat_lat$Species_Latin))
taxa <- tnrs_match_names(names = species_list)
taxa
tree <- tol_induced_subtree(ott_ids= taxa[["ott_id"]])
tree
plot(tree, cex=.8, label.offset =.1, no.margin = TRUE)
str(tree)
is.binary.tree(tree) #TRUE
is.ultrametric(tree) #FALSE - Error: no branch lengths! (will simulate later)
tree$node.label <- "" # remove
tree$tip.label #clean these up
tree$tip.label <- gsub("_ott.*","", tree$tip.label)
plot(tree, cex=.8, label.offset =.1, no.margin = TRUE)
tree <- collapse.singles(tree)
tree$tip.label # column "animal" in the dataset should match these names exactly! 
intersect(unique(dat_lat$Species_Latin), tree$tip.label) #all are matching
#setdiff(unique(dat_lat$Species_Latin), tree$tip.label) #0 need to be changed from
#setdiff(tree$tip.label, unique(dat_lat$Species_Latin)) #0 need to be changed to

### computing branch lengths
tree_bl <- compute.brlen(tree)
plot(tree_bl)
is.binary.tree(tree_bl)
is.ultrametric(tree_bl)
str(tree_bl)
write.tree(tree_bl,file="data/tree_branch_lengths_lat.tre")
#tree_bl <- read.tree(file="data/tree_branch_lengths_lat.tre")
#if you need to remove some species from the tree later (due to working on the subset of the data), use drop.tip function, for example:
#tree_noInsect <- drop.tip(tree, "Bombus_terrestris_audax") # remove "Bombus_terrestris_audax" from the tree
write.csv(dat_lat, "data/data_latencies_with_ES2_tree.csv", row.names = FALSE)
```


############################## Merging Proportion and latency data #############################

```{r merge prop lat}
#dat_prop <- read.csv("data/data_proportions_with_ES_tree.csv")
#dat_lat <- read.csv("data/data_latencies_with_ES2_tree.csv")
#dat_lat <- dplyr::select(dat_lat, -c(Hd_raw, HdVar_raw)) #get rid of _raw columns, if present

####### Rbind latency and proportion data
dat_lat_prop <- rbind(dat_lat, dat_prop) 

dim(dat_lat_prop)
str(dat_lat_prop)

write.csv(dat_lat_prop, "data/data_merged.csv", row.names = FALSE)
```

############## TREE prop+lat

```{r tree prop lat} 
#The function tnrs_match_names returns a data frame that lists the Open Tree identifiers as
#well as other information to help users ensure that the taxa matched are the correct ones

#dat_lat_prop <- read.csv("data/data_merged.csv")
names(dat_lat_prop)
table(dat_lat_prop$Species_Latin)
species_list <- as.character(unique(dat_lat_prop$Species_Latin))
taxa <- tnrs_match_names(names = species_list)
taxa
tree <- tol_induced_subtree(ott_ids= taxa[["ott_id"]])
tree
plot(tree, cex=.8, label.offset =.1, no.margin = TRUE)
str(tree)
is.binary.tree(tree) #TRUE
is.ultrametric(tree) #FALSE - no branch lengths! (will simulate later)
tree$node.label <- "" # remove
tree$tip.label #clean these up
tree$tip.label <- gsub("_ott.*","", tree$tip.label)
plot(tree, cex=.8, label.offset =.1, no.margin = TRUE)
tree <- collapse.singles(tree)
tree$tip.label # column "animal" in the dataset should match these names exactly! 
intersect(unique(dat_lat_prop$Species_Latin), tree$tip.label) #these are matching
setdiff(unique(dat_lat_prop$Species_Latin), tree$tip.label) #matching
setdiff(tree$tip.label, unique(dat_lat_prop$Species_Latin)) #matching
tree_bl <- compute.brlen(tree) ### computing branch lengths
plot(tree_bl)
is.binary.tree(tree_bl)
is.ultrametric(tree_bl)
str(tree_bl)
write.tree(tree_bl,file="data/tree_branch_lengths_lat_prop.tre")
#tree_bl <- read.tree(file="data/tree_branch_lengths_lat_prop.tre")

#if you need to remove some species from the tree later (due to working on the subset of the data), use drop.tip function, for example:
#tree_noInsect <- drop.tip(tree, "Bombus_terrestris_audax") # remove "Bombus_terrestris_audax" from the tree
#write.csv(dat_lat_prop, "data/data_merged.csv", row.names = FALSE)
```


###############################################################################

NEXT: "STEP2_summary.Rmd"
