---
title: "preprocessing"
author: "ML"
date: "11/29/2017"
output: html_document
---

# MA of cognitive bias (optimism) in animal studies.

## STEP1 - preprocessing data

The outcome measures are either letencies or proportions (percent or logit). Need to use different functions for calculating effect sizes.

```{r setup}

sessionInfo() #R version 3.4.2 (2017-09-28)
#Platform: x86_64-apple-darwin15.6.0 (64-bit)
#Running under: macOS Sierra 10.12.6
options(scipen=100)

#install.packages("car", "meta", "metafor", "ape", "dplyr", "ggplot2", "scales", "cowplot")
#install.packages("devtools","fulltxt")
#library(readxl)
#update.packages("fulltxt")
#library(fulltext)
#devtools::install_github("ropensci/rotl", dependencies = TRUE, build_vignette=TRUE)
#install.packages("rotl")
#library(rotl)
#library(ape)
#library(phytools)
#library(dplyr)
#library(tidyr)
#library(ggplot2)
#library(scales)
#library(easyGgplot2)
#library(cowplot)

pacman::p_load(tidyverse, magrittr, fulltext, rotl, ape, dplyr, tidyr)
source("functions.R")
```

################################################# Load MA dataset #############################
                                        
```{r MA_dataset load, eval=TRUE}                                          
#load proportion data from text file:
dat <- read.csv("MA_dataset_2017.csv")
names(dat)
tail(dat)
str(dat) 
dim(dat)

unlist(lapply(dat, function(x) sum(is.na(x)))) #how many NA per numerical column
dat <- dplyr::select(dat, -c(X, X.1)) #get rid of rows with no data (last 2 columns)
dat <- dplyr::filter(dat, !is.na(Better)) #get rid of rows with no data (last empty row)
table(dat$DataSE) #6 SE were missing?
dplyr::filter(dat, DataSE == "no") #Destrez2016, Hernandez2015 (3 rows each)
dat <- dplyr::filter(dat, DataSE != "no") #exclude rows with imputed SE
dat <- droplevels(dat)
table(dat$WithinBetween) # 168 "between", 97 "within"
table(dat$StudyDesign, dat$WithinBetween) #good overlap
dat$EffectID #263 levels for 265 rows, needs fixing
#add comparison ID column
dat$EffectID <- paste("Effect", 1:nrow(dat), sep="_") #add column with comparison ID (unique ID for effect sizes)
dat[,"EffectID"] <- as.factor(dat$EffectID)

dim(dat)
```



```{r data check, eval=TRUE}  
#which means are already logit-transformed?
table(dat$DataScale) #6 data points on logit scale
dat[which(dat$DataScale == "logit"), ]

#find rows with means or SD = 0 for natural scale proportion data
dat[which(dat$Better == 0 & dat$DataScale == "natural"), ] #none
dat[which(dat$BetterSD == 0 & dat$DataScale == "natural"), ] #none
dat[which(dat$Worse == 0 & dat$DataScale == "natural"), ] #2 rows
dat[which(dat$WorseSD == 0 & dat$DataScale == "natural"), ] #2 rows
dat[which(dat$Worse < 0.5 & dat$DataScale == "natural"), ]$Worse #smallest value after 0 is 0.01
dat$Worse[which(dat$Worse == 0 & dat$DataScale == "natural")] <- 0.01 #substitute the 0 values with 0.01
dat[which(dat$WorseSD < 0.5 & dat$DataScale == "natural"), ]$WorseSD #smallest value after 0 is 0.016
dat$WorseSD[which(dat$WorseSD == 0 & dat$DataScale == "natural")] <- 0.01 #substitute the 0 values with 0.01

#find rows with means / 100 > 1 (more than 100%) for the proportion data
dat[which(dat$Better/100 >= 1 & dat$DataScale == "natural" & dat$MeasureType == "proportion"), ] #1 row
dat[which(dat$Worse/100 >= 1 & dat$DataScale == "natural" & dat$MeasureType == "proportion"), ] #1 row
dat[which(dat$Worse/100 > 0.9 & dat$DataScale == "natural" & dat$MeasureType == "proportion"), ]$Worse #largest value before 100 is 95.6
dat$Worse[which(dat$Worse/100 >= 1 & dat$DataScale == "natural" & dat$MeasureType == "proportion")] <- 96 #substitute the >100% value with 95.7
dat[which(dat$Better/100 > 0.9 & dat$DataScale == "natural" & dat$MeasureType == "proportion"), ]$Better #largest value before 100 is 99.3
dat$Better[which(dat$Better/100 >= 1 & dat$DataScale == "natural" & dat$MeasureType == "proportion")] <- 99.4 #substitute the >100% value with 99.4

#find rows with means < 1 (more than 100%) for the percent data
dat[which(dat$Better < 1 & dat$DataScale == "natural" & dat$MeasureType == "proportion"), ] #0 rows
dat[which(dat$Worse < 1 & dat$DataScale == "natural" & dat$MeasureType == "proportion"), ] #3 rows, checked

# #plot
# hist(dat$Worse[which(dat$DataScale == "natural")])
# hist(qlogis(dat$Worse[which(dat$DataScale == "natural")]/100))
# hist(dat$Better[which(dat$DataScale == "natural")])
# hist(qlogis(dat$Better[which(dat$DataScale == "natural")]/100))
# qlogis(dat$Worse[which(dat$DataScale == "natural")]/100)
```


```{r calculate ES, eval=TRUE}  
#subset dataframe and recalculate means and variances to the same scale using custom functions for specific data types and scales
 table(dat$MeasureType, dat$DataScale) # 138 "latency", 127 "proportion", including 6 logit

## latency data subset
 dat_lat <- dplyr::filter(dat, MeasureType == "latency") #subset latency data
 dim(dat_lat) 
 table(dat_lat$WithinBetween) #by stydy design type
 dat_lat2 <- dat_lat %>% calc_ES_latency(Worse, WorseSD, WorseN, Better, BetterSD, BetterN, WithinBetween, adjusted=TRUE, type="lnorm") 

## logit of proportion data subset
 dat_prop_logit <- dplyr::filter(dat, MeasureType == "proportion" & DataScale == "logit") #subset proportion data (percentage) on logit scale
 dim(dat_prop_logit)
 table(dat_prop_logit$WithinBetween) #by stydy design type
 dat_prop_logit2 <- dat_prop_logit %>% calc_ES_proportion(Worse, WorseSD, WorseN, Better, BetterSD, BetterN, WithinBetween, adjusted=TRUE, type="logit") 
 
## percent data subset
 dat_prop_pct <- dplyr::filter(dat, MeasureType == "proportion" & DataScale == "natural") #subset proportion data (percentage) on natural scale
 dim(dat_prop_pct) 
 table(dat_prop_pct$WithinBetween) #by stydy design type
 dat_prop_pct2 <- dat_prop_pct %>% calc_ES_proportion(Worse, WorseSD, WorseN, Better, BetterSD, BetterN, WithinBetween, adjusted=TRUE, type="percent")  
 

## merge back the subsets
dat2 <- rbind(dat_lat2, dat_prop_logit2, dat_prop_pct2)
names(dat2)
dat2$d
hist(dat2$d)
hist(dat2$Vd)

dat2$Species_Latin <- as.character(dat2$ScientificName) #Make new column in the data frame and adjust species names
write.csv(dat2, "data_with_ES.csv", row.names = FALSE)

#View(dplyr::filter(dat2, d > 4)) #look at effect sizes > 4  checked against the original papers
#View(dplyr::filter(dat2, d < (-2))) #look at effect sizes <  -4  checked agains the original papers
```


```{r clean, eval=FALSE}  
# #remove odd one?
# #dat2[dat2$ArticleID == "Doyle2011b", ]
# dat2 <- dat2[dat2$ArticleID != "Doyle2011b", ] #sheep long terms stress. Tested 3 times ..habituation? Use day 1?
# dim(dat2)
```

############## TREE 

Prepare phyogenetic tree for the included species  

```{r  tree, eval=TRUE}
#The function tnrs_match_names returns a data frame that lists the Open Tree identifiers as
#well as other information to help users ensure that the taxa matched are the correct ones

names(dat2)
table(dat2$ScientificName)
unique(dat2$Species_Latin)

species_list <- as.character(unique(dat2$Species_Latin))
taxa <- tnrs_match_names(names = species_list) #call rotl function to find these species on OTL
#taxa
tree <- tol_induced_subtree(ott_ids= taxa[["ott_id"]])
tree
plot(tree, cex=.8, label.offset =.1, no.margin = TRUE)
str(tree) # no branch lengths
is.binary.tree(tree) #TRUE 
tree$node.label <- "" # remove
tree$tip.label <- gsub("_ott.*","", tree$tip.label) #clean up tip labels
plot(tree, cex=.8, label.offset =.1, no.margin = TRUE)
tree <- collapse.singles(tree)
intersect(unique(dat2$Species_Latin), tree$tip.label) #all are matching

### computing branch lengths
tree_bl <- compute.brlen(tree)
plot(tree_bl)
is.binary.tree(tree_bl)
is.ultrametric(tree_bl)
str(tree_bl)
#if you need to remove some species from the tree later (due to working on the subset of the data), use drop.tip function, for example:
#tree_noInsect <- drop.tip(tree, "Bombus_terrestris_audax") # remove "Bombus_terrestris_audax" from the tree

write.tree(tree_bl,file="tree_all.tre")
#tree <- read.tree(file="tree_all.tre")
```



###############################################################################

NEXT: "STEP2_summary.Rmd"
